import customtkinter as ctk
from tkinter import scrolledtext
import threading, queue
from transformers import pipeline

# --- Global Style Configuration ---
ctk.set_appearance_mode("Dark")
ctk.set_default_color_theme("blue")

class HarryGPT(ctk.CTk):
    def __init__(self):
        super().__init__()
        self.title("Harry AI â€” Advanced GPT Assistant")
        self.geometry("1100x850")

        # Grid Layout
        self.grid_columnconfigure(1, weight=1)
        self.grid_rowconfigure(0, weight=1)

        # --- Sidebar ---
        self.sidebar = ctk.CTkFrame(self, width=240, corner_radius=0)
        self.sidebar.grid(row=0, column=0, rowspan=2, sticky="nsew")
        
        self.logo = ctk.CTkLabel(self.sidebar, text="HARRY GPT", font=ctk.CTkFont(size=24, weight="bold"))
        self.logo.pack(pady=30)
        
        self.new_chat_btn = ctk.CTkButton(self.sidebar, text="New Session", command=self.clear_chat)
        self.new_chat_btn.pack(pady=10, padx=20)

        self.status_var = ctk.StringVar(value="Status: Initializing Core...")
        self.status_lbl = ctk.CTkLabel(self.sidebar, textvariable=self.status_var, font=("Inter", 11))
        self.status_lbl.pack(side="bottom", pady=20)

        # --- Chat Interface ---
        self.chat_display = scrolledtext.ScrolledText(self, state='disabled', wrap='word', 
                                                     bg="#1a1a1a", fg="#ececf1", font=("Inter", 12),
                                                     padx=25, pady=25, borderwidth=0)
        self.chat_display.grid(row=0, column=1, padx=20, pady=20, sticky="nsew")

        # --- Input Console ---
        self.input_frame = ctk.CTkFrame(self, fg_color="transparent")
        self.input_frame.grid(row=1, column=1, padx=20, pady=(0, 20), sticky="ew")
        
        self.entry = ctk.CTkTextbox(self.input_frame, height=100, font=("Inter", 12), corner_radius=15)
        self.entry.pack(side='left', fill='x', expand=True, padx=(0, 10))
        
        self.send_btn = ctk.CTkButton(self.input_frame, text="Execute", width=120, height=45, 
                                     command=self.on_send, corner_radius=8)
        self.send_btn.pack(side='right')

        # --- AI Brain State ---
        self.history = []
        self.q = queue.Queue()
        self.after(100, self.process_queue)
        
        # Load the neural network in the background
        threading.Thread(target=self.load_engine, daemon=True).start()

    def load_engine(self):
        try:
            # FLAN-T5-Large is selected for its instruction-following capabilities
            self.model = pipeline("text2text-generation", model="google/flan-t5-large")
            self.status_var.set("Status: Core Online")
        except Exception as e:
            self.status_var.set("Status: Load Error")
            print(f"Neural Error: {e}")

    def on_send(self):
        user_input = self.entry.get("1.0", "end").strip()
        if not user_input: return
        
        self.entry.delete("1.0", "end")
        self.update_display("USER", user_input)
        
        self.status_var.set("Harry is thinking...")
        threading.Thread(target=self.think, args=(user_input,), daemon=True).start()

    def think(self, user_input):
        # 1. Identity Anchor: Defined by interests in engineering and strategy games
        system_identity = (
            "You are Harry, a witty and brilliant Computer Engineering AI assistant. "
            "You are highly articulate, technical, and never repeat the user's input. "
            "You specialize in Java, Python, and grand strategy games like EU4.\n\n"
        )
        
        # 2. Memory Context: Using a sliding window to keep focus
        recent_context = self.history[-4:] 
        conversation_flow = ""
        for turn in recent_context:
            conversation_flow += f"{turn['speaker']}: {turn['text']}\n"
        
        # 3. Prompt Formatting: Structured to avoid the 'echo' effect
        final_prompt = f"{system_identity}### Conversation History:\n{conversation_flow}### New Question:\nUSER: {user_input}\nHARRY:"

        # 4. GPT-Style Decoding Parameters
        # Repetition penalty is set high to force original generation
        # Temperature and Top-P allow for creative, diverse responses
        try:
            result = self.model(
                final_prompt,
                max_new_tokens=300,
                do_sample=True,
                temperature=0.85,
                top_p=0.92,
                repetition_penalty=3.5 
            )
            response = result[0]['generated_text'].strip()
            
            # Post-Generation Cleanup
            for tag in ["HARRY:", "Harry:", "Assistant:", "USER:"]:
                response = response.replace(tag, "")
            response = response.strip()
        except:
            response = "Error: Neural inference failed. Please re-run the kernel."

        self.q.put(response)
        self.history.append({"speaker": "USER", "text": user_input})
        self.history.append({"speaker": "HARRY", "text": response})

    def update_display(self, speaker, text):
        self.chat_display.configure(state='normal')
        tag = speaker
        header = f"{speaker}\n"
        self.chat_display.insert('end', header, tag)
        self.chat_display.insert('end', f"{text}\n\n")
        
        # Styling for chat bubbles
        if speaker == "USER":
            self.chat_display.tag_config(tag, foreground="#10a37f", font=("Inter", 11, "bold"))
        else:
            self.chat_display.tag_config(tag, foreground="#5dade2", font=("Inter", 11, "bold"))
            
        self.chat_display.see('end')
        self.chat_display.configure(state='disabled')

    def process_queue(self):
        try:
            while True:
                response = self.q.get_nowait()
                self.update_display("HARRY", response)
                self.status_var.set("Status: Core Online")
        except queue.Empty:
            pass
        self.after(100, self.process_queue)

    def clear_chat(self):
        self.chat_display.configure(state='normal')
        self.chat_display.delete("1.0", "end")
        self.chat_display.configure(state='disabled')
        self.history = []
        self.status_var.set("Status: Memory Wiped")

if __name__ == "__main__":
    app = HarryGPT()
    app.mainloop()
